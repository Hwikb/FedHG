## This is the code for FedHG
![image1](https://cdn.jsdelivr.net/gh/Hwikb/pic_bed@main/img/FedHGflowchart.jpg)

To address data heterogeneity in federated learning, we propose a method called FedHG. A generator is trained on the server side with a KL loss to enhance its sensitivity to different labels. Clients utilize the feature distributions generated by the generator to adaptively aggregate the head parameters of their local and global models, thereby capturing the global knowledge while preserving valuable local information. FedHG outperforms nine classic algorithms across four datasets of varying complexity under two heterogeneous settings.

Next,I introduce how to use the code

- In dataset,there are four files,to generating and spliting dataset.Such as,if you want to generate MNIST dataset,you can input
```py
python generate_MNIST.py noniid - dir" 
```
  "dir" is Practical heterogeneous setting, meanwile "pat" is Pathological heterogeneous setting.

- After spliting dataset,you can run FedHG,start by switching directories"cd./System",and inputing
```py
python main.py -data MNIST -nb 10 -m cnn -gr 200 -did 0 -algo FedHG".
```
